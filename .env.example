# Server Configuration
PORT=3000
NODE_ENV=development

# Database Configuration
DATABASE_URL=postgresql://gm_user:gm_password@localhost:5432/gm_assistant

# Redis Configuration
REDIS_URL=redis://localhost:6379

# S3-Compatible Storage (MinIO)
S3_ENDPOINT=http://localhost:9000
S3_BUCKET=gm-assistant
S3_ACCESS_KEY=minio_admin
S3_SECRET_KEY=minio_password

# LLM Configuration
LLM_PROVIDER=ollama          # "ollama" for local or "google" for Google AI (Gemini)
LLM_MODEL=gemma3:1b          # Use "gemini-2.5-flash" with google provider
LLM_BASE_URL=http://localhost:11434
LLM_TIMEOUT=60000
LLM_MAX_TOKENS=2048
LLM_TEMPERATURE=0.7

# Google AI / Gemini (required when LLM_PROVIDER=google)
# GOOGLE_AI_API_KEY=your-api-key-here

# Authentication
JWT_SECRET=your-secret-key-here
JWT_EXPIRES_IN=7d

# Session Configuration
SESSION_SECRET=your-session-secret-here
SESSION_MAX_AGE_DAYS=30
SESSION_UPDATE_AGE_HOURS=1

# OCR Service (optional - scanned PDF support disabled if not set)
# Start with: docker compose --profile with-ocr up -d ocr
 OCR_SERVICE_URL=http://localhost:8080
 OCR_TIMEOUT=300000

# PostHog Analytics (optional - metrics disabled if not set)
# POSTHOG_API_KEY=phc_your_project_api_key
# POSTHOG_HOST=https://us.i.posthog.com
